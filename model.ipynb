{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 名称      | 含义 |\n",
    "| ----------- | ----------- |\n",
    "| n_user      | 用户数       |\n",
    "| n_item   | 交互项目数        |\n",
    "| train_data   | 训练集        |\n",
    "| eval_data   | 验证集        |\n",
    "| test_data   | 测试集        |\n",
    "| adj_item   | 行:用户 列:用户产生的交互编号 每个用户采样20个交互        |\n",
    "| n_classes   | 待分类的结果数量 例如性别就是男、女2类        |\n",
    "| ratings_np   | 从ratings文件中读取的原始数据 numpy数组 每个用户一行 列分别是(用户id, 交互id, 性别)        |\n",
    "| adj_user   | adj_user[i][j]: 与用户i产生过的某个用户id (没有顺序, 是随机采样的) |\n",
    "| n_entity   | 知识库中实体的个数(头尾做union)        |\n",
    "| n_relation   | 知识库中关系的个数(头尾做union)        |\n",
    "| adj_entity   | adj_entity[i]: 与实体i有关系的实体集合(采样)        |\n",
    "| adj_relation   | adj_relation[i]: 与实体i有关系的关系(采样)        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载并预处理数据\n",
    "def read_file(filename):\n",
    "  with open('{}.npy'.format(filename), 'rb') as f:\n",
    "    ret = np.load(f)\n",
    "  return ret\n",
    "\n",
    "n_user, n_item, n_entity, n_relation, n_classes = read_file('n_file')     \n",
    "train_data = read_file('train_data')\n",
    "eval_data = read_file('eval_data')\n",
    "test_data = read_file('test_data')    \n",
    "adj_entity = read_file('adj_entity') \n",
    "adj_relation = read_file('adj_relation')\n",
    "adj_item = read_file('adj_item')   \n",
    "adj_entity = read_file('adj_entity')   \n",
    "ratings_np = read_file('ratings_np') \n",
    "adj_user = read_file('adj_user')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock命令行参数\n",
    "arg = {}\n",
    "arg['ratio'] = 1\n",
    "arg['n_interact'] = 20\n",
    "arg['n_neighbors'] = 20\n",
    "arg['dataset'] = 'movie'\n",
    "arg['mission'] = 'gender'\n",
    "arg['neighbor_sample_size'] = 4\n",
    "arg['dim'] = 32\n",
    "arg['lr'] = 0.02\n",
    "arg['l2_weight'] = 0.001\n",
    "arg['n_iter'] = 2\n",
    "arg['batch_size'] = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建初始值\n",
    "user_indicies = tf.placeholder(dtype=tf.int64, shape=[None], name='user_indicies')\n",
    "item_indicies = tf.placeholder(dtype=tf.int64, shape=[None], name='item_indicies')\n",
    "labels = tf.placeholder(dtype=tf.int64, shape=[None], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer():\n",
    "  # 这个初始化器是用来使得每一层输出的方差应该尽量相等。\n",
    "  return tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建embedding矩阵作为用户特征输入 并构建训练参数矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "dim = arg['dim']\n",
    "# 用户特征embedding矩阵\n",
    "user_emb_matrix = tf.get_variable(\n",
    "            shape=[n_user, dim], initializer=get_initializer(), name='user_emb_matrix')\n",
    "# 实体特征embedding矩阵\n",
    "entity_emb_matrix = tf.get_variable(\n",
    "            shape=[n_entity, dim], initializer=get_initializer(), name='entity_emb_matrix')\n",
    "# 关系embedding矩阵\n",
    "relation_emb_matrix = tf.get_variable(\n",
    "    shape=[n_relation, dim], initializer=get_initializer(), name='relation_emb_matrix')\n",
    "# 输出层参数w\n",
    "output_weights = tf.get_variable(\n",
    "    shape=[dim, n_classes], initializer=get_initializer(),name='output_weights1')\n",
    "# 输出层偏置\n",
    "output_bias = tf.get_variable(\n",
    "    shape=[n_classes], initializer=tf.zeros_initializer(), name='output_bias1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取近邻实体与关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = tf.expand_dims(item_indicies, axis=1) # item_indicies:[n] -> seeds:[n,1] \n",
    "seeds.shape # 从行向量变成列向量了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 收集算法\n",
    "1. 对于用户u的交互实体集合$N_i(u)$中的每一个实体$e_i^0$,收集其近邻实体集合$N_i(e_i^0)$, 集合中的每一个实体直接与实体$e_i^0$相连。 则有关系r_{e_i^0,e_j^1}表示实体$e_i^0$和实体$e_j^1$之间的关系,其中$e^1_j\\in N_i(e_i^0)$。 \n",
    "2. 对于每一个$N_i(e_i^0)$中的实体$e_j^1$,进行近邻实体获取,得到$e_j^1$的近邻实体集合$N_i(e_j^1)$。 \n",
    "3. 对$e_j^1$的近邻实体集合$N_i(e_j^1)$中的实体$e_k^2$,进行近邻实体获取,直到递归次数达到H次,递归收集过程终止。 \n",
    "\n",
    "\n",
    "![迭代搜集近邻实体算法](assets/alg3.1_get_neighbor_entities.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37473, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_entity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下构建临近矩阵\n",
    "(意义不明)\n",
    "- entities\n",
    "- interact_item\n",
    "- neighbor_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [seeds] # entities:[1,n,1]\n",
    "relations = []\n",
    "n_iter = arg['n_iter'] # 迭代次数是超参\n",
    "batch_size = arg['batch_size']\n",
    "for i in range(n_iter):\n",
    "    # tf.gather(a,b): 在tensor a中获取下标为 b(可以是列表)的tensor\n",
    "    # tf.gather(adj_entity, entities[i]) -> [n,1,4]\n",
    "    neighbor_entities = tf.reshape(tf.gather(adj_entity, entities[i]), [batch_size, -1]) # 这是在干什么？？？\n",
    "    neighbor_relations = tf.reshape(tf.gather(adj_relation, entities[i]), [batch_size, -1])\n",
    "    entities.append(neighbor_entities) # 每次迭代用上一次迭代结果的entities继续寻找邻居\n",
    "    relations.append(neighbor_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = tf.expand_dims(user_indicies, axis=1)\n",
    "# 获取user交互过的电影 n=10\n",
    "interact_item = tf.reshape(tf.gather(adj_item, users), [batch_size, -1])\n",
    "neighbor_users = tf.reshape(tf.gather(adj_user, users), [batch_size, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从user_emb_matrix中取出user_indicies列表对应的列\n",
    "user_embedding = tf.nn.embedding_lookup(user_emb_matrix, user_indicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取该batch下的相应实体和关系的嵌入向量\n",
    "\n",
    "entity_vectors和relation_vectors里面存的是[[seeds],[一跳邻居],[二跳邻居]]的embedding\n",
    "\n",
    "其中每个元素的形状,[batch_size,n_neighers,dim],[batch_size,n_neighbers^2,dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_vectors = [tf.nn.embedding_lookup(entity_emb_matrix, i) for i in entities]\n",
    "relation_vectors = [tf.nn.embedding_lookup(relation_emb_matrix, i) for i in relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils to generate Layer ids\n",
    "LAYER_IDS = {}\n",
    "def get_layer_id(layer_name=''):\n",
    "    if layer_name not in LAYER_IDS:\n",
    "        LAYER_IDS[layer_name] = 0\n",
    "        return 0\n",
    "    else:\n",
    "        LAYER_IDS[layer_name] += 1\n",
    "        return LAYER_IDS[layer_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "class Aggregator(object):\n",
    "  def __init__(self, batch_size, dim, dropout, act, name) -> None:\n",
    "      super().__init__()\n",
    "      if not name:\n",
    "        layer = self.__class__.__name__.lower()\n",
    "        name = layer + '_' + str(get_layer_id(layer))\n",
    "      self.name = name\n",
    "      self.dropout = dropout\n",
    "      self.act = act\n",
    "      self.batch_size = batch_size\n",
    "      self.dim = dim\n",
    "\n",
    "  def __call__(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings):\n",
    "      return self._call(self_vectors, neighbor_vectors, neighbor_relations, user_embeddings)\n",
    "\n",
    "  @abstractmethod\n",
    "  def _call(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings):\n",
    "    '''\n",
    "    Parameters:\n",
    "      self_vectors - 实体自身的表示向量（当前跳数h下的实体嵌入向量） 大小[batch_size, -1, dim]\n",
    "      neighbor_vectors - 当前实体近邻实体的表示向量（h+1跳的实体嵌入向量）大小[batch_size, -1, n_neighbor, dim]\n",
    "      neighbor_relations - 当前跳数h下的关系嵌入向量 大小[batch_size, -1, n_neighbor, dim]\n",
    "      user_embeddings - 用户嵌入向量 大小[batch_size, dim]\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "  def _mix_neighbor_vectors(self, neighbor_vectors, neighbor_relations, user_embeddings):\n",
    "    user_embeddings = tf.reshape(user_embeddings, [self.batch_size, 1, 1, self.dim])\n",
    "    # 计算用户与关系的相似度得分后取均值\n",
    "    user_relation_scores = tf.reduce_mean(user_embeddings * neighbor_relations, axis=-1)\n",
    "    # 送入softmax归一化\n",
    "    user_relation_scores_normalized = tf.nn.softmax(user_relation_scores, dim=-1)\n",
    "    user_relation_scores_normalized = tf.expand_dims(user_relation_scores_normalized, axis=-1) # [batch_size, -1, n_neighbor, 1]\n",
    "    # 用户_关系相似度与近邻实体集合以线性方式结合\n",
    "    # aixs=2是将每个实体的近邻实体结合 上面的-1是把embedding的dim结合 （为啥呀？？）\n",
    "    neighbors_aggregated = tf.reduce_mean(user_relation_scores_normalized * neighbor_vectors, axis=2) # [batch_size, -1, dim]\n",
    "    return neighbors_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAggregator(Aggregator):\n",
    "  def __init__(self, batch_size, dim, dropout=0., act=tf.nn.relu, name=None):\n",
    "    super(ConcatAggregator, self).__init__(batch_size, dim, dropout, act, name)\n",
    "\n",
    "    with tf.variable_scope(self.name):\n",
    "        self.weights = tf.get_variable(\n",
    "            shape=[self.dim * 2, self.dim], initializer=tf.contrib.layers.xavier_initializer(), name='weights')\n",
    "        self.bias = tf.get_variable(shape=[self.dim], initializer=tf.zeros_initializer(), name='bias')\n",
    "\n",
    "  def _call(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings):\n",
    "    # [batch_size, -1, dim]\n",
    "    neighbors_agg = self._mix_neighbor_vectors(neighbor_vectors, neighbor_relations, user_embeddings)\n",
    "    \n",
    "    # 论文中用的是拼接的方式结合本层实体和近邻实体表示向量\n",
    "    output = tf.concat([self_vectors, neighbors_agg], axis=-1) # [batch_size, -1, dim * 2]\n",
    "    output = tf.reshape(output, [-1, self.dim * 2]) # [-1, dim * 2]\n",
    "    output = tf.nn.dropout(output, keep_prob=1-self.dropout)\n",
    "\n",
    "    output = tf.matmul(output, self.weights) + self.bias # [-1, dim]\n",
    "\n",
    "    output = tf.reshape(output, [self.batch_size, -1, self.dim]) # [batch_size, -1, dim]\n",
    "\n",
    "    return self.act(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregators=[]\n",
    "n_neighbor=arg['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregate entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "    # 初始化聚合器 聚合的过程与塔式结构有一点类似\n",
    "    if i == n_iter - 1: \n",
    "        aggregator = ConcatAggregator(batch_size, dim, act=tf.nn.tanh, dropout=0.4) # 最后一次迭代用tanh激活\n",
    "    else:\n",
    "        aggregator = ConcatAggregator(batch_size, dim, dropout=0.4) # 其余用relu\n",
    "    aggregators.append(aggregator)\n",
    "\n",
    "    entity_vectors_next_iter = []\n",
    "    # 对应论文算法1 5~8行\n",
    "    for hop in range(n_iter - i):\n",
    "        shape = [batch_size, -1, n_neighbor, dim]\n",
    "        # 聚合器参数分别是，实体自身的embedding，实体邻居的embedding，\n",
    "        # 实体与邻居实体相连的关系embedding，用户embedding（用于计算个g(u,r)）\n",
    "        vector = aggregator(self_vectors=entity_vectors[hop],\n",
    "                            neighbor_vectors=tf.reshape(entity_vectors[hop + 1], shape),\n",
    "                            neighbor_relations=tf.reshape(relation_vectors[hop], shape),\n",
    "                            user_embeddings=user_embedding)\n",
    "        entity_vectors_next_iter.append(vector)\n",
    "    # 更新实体embedding，因为在上面的for循环中进行了聚合\n",
    "    entity_vectors = entity_vectors_next_iter\n",
    "\n",
    "item_embeddings = tf.reshape(entity_vectors[0], [batch_size, dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregate users\n",
    "和上面聚集实体几乎是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAggregator(object):\n",
    "    def __init__(self, batch_size, dim, dropout, act, name):\n",
    "        if not name:\n",
    "            layer = self.__class__.__name__.lower()\n",
    "            name = layer + '_' + str(get_layer_id(layer))\n",
    "        self.name = name\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings, neighbors_embeddings):\n",
    "        outputs = self._call(self_vectors, neighbor_vectors, neighbor_relations, user_embeddings, neighbors_embeddings)\n",
    "        return outputs\n",
    "\n",
    "    @abstractmethod\n",
    "    def _call(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings, neighbors_embeddings):\n",
    "        # dimension:\n",
    "        # self_vectors: [batch_size, -1, dim]\n",
    "        # neighbor_vectors: [batch_size, -1, n_neighbor, dim]\n",
    "        # neighbor_relations: [batch_size, -1, n_neighbor, dim]\n",
    "        # user_embeddings: [batch_size, dim]\n",
    "        pass\n",
    "\n",
    "    def _mix_neighbor_vectors(self, neighbor_vectors, neighbor_relations, user_embeddings):\n",
    "        # [batch_size, 1, dim]\n",
    "        user_embeddings = tf.reshape(user_embeddings, [self.batch_size, 1, self.dim])\n",
    "\n",
    "        # [batch_size, n_neighbor]\n",
    "        # 计算用户关系得分时，根据最后一个维度方向上的平均数（dims个值）进行标准化得分，softmax将得分标准化的同时，让它们和为1\n",
    "        user_relation_scores = tf.reduce_mean(user_embeddings * neighbor_relations, axis=-1)\n",
    "        user_relation_scores_normalized = tf.nn.softmax(user_relation_scores, dim=-1)\n",
    "\n",
    "        # [batch_size, n_neighbor, 1]\n",
    "        user_relation_scores_normalized = tf.expand_dims(user_relation_scores_normalized, axis=-1)\n",
    "\n",
    "        # [batch_size, dim]\n",
    "        neighbors_aggregated = tf.reduce_mean(user_relation_scores_normalized * neighbor_vectors, axis=1)\n",
    "        return neighbors_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumAggregator(UserAggregator):\n",
    "    def __init__(self, batch_size, dim, dropout=0., act=tf.nn.relu, name=None):\n",
    "        super(SumAggregator, self).__init__(batch_size, dim, dropout, act, name)\n",
    "\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.weights = tf.get_variable(\n",
    "                shape=[self.dim * 2, self.dim], initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                name='user_agg_weights')\n",
    "            self.bias = tf.get_variable(shape=[self.dim], initializer=tf.zeros_initializer(), name='user_agg_bias')\n",
    "\n",
    "    def _call(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings, neighbors_embeddings):\n",
    "        # [batch_size, -1, dim]\n",
    "        neighbors_agg = self._mix_neighbor_vectors(neighbor_vectors, neighbor_relations, user_embeddings)\n",
    "        # # below 3 row test for HKGCN without neighbor user\n",
    "        neighbors_user = self._mix_neighbor_vectors(neighbors_embeddings, neighbors_embeddings, user_embeddings)\n",
    "        output = tf.concat([neighbors_user, neighbors_agg], axis=-1)\n",
    "        output = tf.reshape(output, [-1, self.dim * 2])\n",
    "        # output = tf.reshape(neighbors_agg, [-1, self.dim])\n",
    "        # [-1, dim]\n",
    "        # output = tf.reshape(self_vectors + neighbors_agg, [-1, self.dim])\n",
    "\n",
    "        output = tf.nn.dropout(output, keep_prob=1 - self.dropout)\n",
    "        output = tf.matmul(output, self.weights) + self.bias\n",
    "\n",
    "        return self.act(output + self_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = tf.nn.embedding_lookup(user_emb_matrix, user_indicies)\n",
    "\n",
    "# [batch_size,n_interact,dim]\n",
    "interactItemEmb = tf.nn.embedding_lookup(entity_emb_matrix, interact_item)\n",
    "neighbor_usersEmb = tf.nn.embedding_lookup(user_emb_matrix, neighbor_users)\n",
    "\n",
    "aggragator = SumAggregator(batch_size, dim, act=tf.nn.tanh)\n",
    "user_embeddings = aggragator(user_embeddings, interactItemEmb, interactItemEmb, user_embeddings, neighbor_usersEmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.matmul(user_embeddings, output_weights) + output_bias"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0293982cc521ba79463c97bcbf6060ec5665b6d4557db7071378f3862020d1c"
  },
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('hkgcn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
